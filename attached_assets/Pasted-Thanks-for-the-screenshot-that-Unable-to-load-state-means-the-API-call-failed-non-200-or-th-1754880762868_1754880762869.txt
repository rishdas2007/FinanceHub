Thanks for the screenshot—that “Unable to load …” state means the **API call failed** (non-200 or threw), not just “no data.” The most likely culprit is the **array filter in SQL** I gave you (`ANY($1)` / `::text[]`)—it often trips drivers/Drizzle bindings and bubbles a 500. Let’s fix that first and add guardrails so the tiles never error.

Below is a **surgical patch** for both controllers that:

* Uses a **safe `unnest($1::text[])` join** for symbol lists (works with `pg`/Drizzle consistently).
* Adds **defensive nulls**, and never throws—falls back to `{success:true, data:[]}`.
* Adds quick **console logs** so you’ll see the real reason if something still breaks.

---

# 1) ETF Movers — fixed controller

```ts
// server/controllers/movers-etf.controller.ts
import { sql } from 'drizzle-orm';
import { db } from '../db';
import { getCache, setCache, getLastGood, setLastGood } from '../cache/unified-dashboard-cache';
import { MOVERS } from '../config/movers';
import { loadDailyCloses } from '../services/history/load-daily-closes.service';

function classify(z: number | null) {
  if (z == null) return 'NEUTRAL';
  if (z <= MOVERS.Z_THRESH_BUY)  return 'BUY';
  if (z >= MOVERS.Z_THRESH_SELL) return 'SELL';
  return 'NEUTRAL';
}

export const getEtfMovers = async (req, res) => {
  const horizon = String(req.query.horizon || MOVERS.ETF_DEFAULT_HORIZON).toUpperCase();
  const limit   = Math.max(1, Math.min(24, Number(req.query.limit) || 12));

  const raw = String(req.query.universe || 'SPY,XLK,XLF,XLV,XLY,XLI,XLC,XLE,XLP,XLU,IYR,IWM');
  const universe = Array.from(new Set(raw.split(',').map(s => s.trim().toUpperCase()).filter(Boolean)));
  if (!universe.includes('SPY')) universe.unshift('SPY');

  const cacheKey = `movers:etf:${horizon}:${universe.join('|')}:v2`;
  const cached = await getCache(cacheKey);
  if (cached) return res.json({ success: true, data: cached, cached: true });

  try {
    // --- Prices & pct change (safe array param via UNNEST) ---
    const pricesQ = await db.execute(sql`
      with u as (select unnest(${universe}::text[]) as symbol),
      last2 as (
        select b.symbol, b.ts_utc, b.close,
               row_number() over (partition by b.symbol order by b.ts_utc desc) rn
        from equity_daily_bars b
        join u using(symbol)
      )
      select l.symbol,
             l.close as price,
             (l.close - p.close) / nullif(p.close,0)::float as pct_change
      from (select symbol, close from last2 where rn=1) l
      left join (select symbol, close from last2 where rn=2) p using(symbol);
    `);

    const priceMap = new Map<string, {price:number|null; pctChange:number|null}>();
    for (const r of pricesQ.rows as any[]) {
      priceMap.set(r.symbol, { price: Number(r.price ?? null), pctChange: Number(r.pct_change ?? null) });
    }

    // --- Z-scores (safe array param via UNNEST) ---
    const zQ = await db.execute(sql`
      with u as (select unnest(${universe}::text[]) as symbol),
      mx as (
        select f.symbol, max(f.asof_date) as d
        from equity_features_daily f
        join u using(symbol)
        where f.horizon = ${horizon}
        group by f.symbol
      )
      select f.symbol, f.z_close
      from equity_features_daily f
      join mx on mx.symbol=f.symbol and mx.d=f.asof_date
      where f.horizon = ${horizon};
    `);
    const zMap = new Map<string, number|null>();
    for (const r of zQ.rows as any[]) zMap.set(r.symbol, r.z_close == null ? null : Number(r.z_close));

    // --- Spark helper (30D daily closes) ---
    async function spark(symbol: string) {
      const series = await loadDailyCloses(symbol, MOVERS.ETF_SPARK_DAYS);
      return (series ?? []).map(p => ({ t: new Date(p.date).getTime(), value: Number(p.close) }));
    }

    // --- Assemble payload ---
    const benchSym = 'SPY';
    const bench = {
      symbol: benchSym,
      price: priceMap.get(benchSym)?.price ?? null,
      pctChange: priceMap.get(benchSym)?.pctChange ?? null,
      zScore: zMap.get(benchSym) ?? null,
      signal: classify(zMap.get(benchSym) ?? null),
      spark: await spark(benchSym)
    };

    const rows = [];
    for (const s of universe) {
      if (s === benchSym) continue;
      const z = zMap.get(s) ?? null;
      const signal = classify(z);
      if (signal === 'NEUTRAL') continue;
      rows.push({
        symbol: s,
        price: priceMap.get(s)?.price ?? null,
        pctChange: priceMap.get(s)?.pctChange ?? null,
        zScore: z,
        signal,
        spark: await spark(s)
      });
      if (rows.length >= limit) break;
    }

    const payload = { benchmark: bench, signals: rows };
    await setCache(cacheKey, payload, MOVERS.CACHE_TTL_ETF_MS);
    await setLastGood(cacheKey, payload);
    return res.json({ success: true, data: payload });
  } catch (err) {
    console.error('[movers/etf] error', err);
    const last = await getLastGood(cacheKey);
    if (last) return res.json({ success: true, data: last, warning: 'stale_lastGood' });
    return res.json({ success: true, data: { benchmark: null, signals: [] }, warning: 'data_unavailable' });
  }
};
```

---

# 2) Economic Movers — fixed controller

```ts
// server/controllers/movers-econ.controller.ts
import { sql } from 'drizzle-orm';
import { db } from '../db';
import { getCache, setCache, getLastGood, setLastGood } from '../cache/unified-dashboard-cache';
import { MOVERS } from '../config/movers';

async function spark12m(seriesId: string, transform: string) {
  const q = await db.execute(sql`
    with raw as (
      select period_end::date as pe, value_std
      from econ_series_observation
      where series_id = ${seriesId}
        and transform_code = ${transform}
        and period_end >= date_trunc('month', current_date) - interval '12 months'
    ),
    bucket as (
      select date_trunc('month', pe) as m_end, pe, value_std from raw
    ),
    last_per_month as (
      select distinct on (m_end) m_end::date as period_end, value_std
      from bucket
      order by m_end, pe desc
    )
    select period_end, value_std
    from last_per_month
    order by period_end asc;
  `);
  return (q.rows as any[]).map(r => ({ t: Date.parse(r.period_end), value: Number(r.value_std) }));
}

export const getEconMovers = async (req, res) => {
  const limit = Math.max(1, Math.min(10, Number(req.query.limit) || 5));
  const cacheKey = `movers:econ:${limit}:v2`;
  const cached = await getCache(cacheKey);
  if (cached) return res.json({ success: true, data: cached, cached: true });

  try {
    // Latest NON-DAILY series (default transform, coalesced)
    const latest = await db.execute(sql`
      with latest as (
        select d.series_id,
               d.display_name,
               coalesce(nullif(d.default_transform,''),'LEVEL') as default_transform,
               d.standard_unit,
               max(o.period_end) as last_period
        from econ_series_def d
        join econ_series_observation o
          on o.series_id = d.series_id
         and o.transform_code = coalesce(nullif(d.default_transform,''),'LEVEL')
         and o.freq <> 'D'
        group by d.series_id, d.display_name, d.default_transform, d.standard_unit
      )
      select * from latest
      order by last_period desc
      limit ${limit};
    `);

    const out = [];
    for (const r of latest.rows as any[]) {
      const { series_id, display_name, default_transform, standard_unit, last_period } = r;

      const cur = await db.execute(sql`
        select period_end, value_std
        from econ_series_observation
        where series_id = ${series_id}
          and transform_code = ${default_transform}
          and period_end = ${last_period}
        limit 1;
      `);
      const prior = await db.execute(sql`
        select period_end, value_std
        from econ_series_observation
        where series_id = ${series_id}
          and transform_code = ${default_transform}
          and period_end < ${last_period}
        order by period_end desc
        limit 1;
      `);

      const currentVal = cur.rows[0]?.value_std ?? null;
      const priorVal   = prior.rows[0]?.value_std ?? null;

      const zq = await db.execute(sql`
        select level_z
        from econ_series_features
        where series_id = ${series_id}
          and transform_code = ${default_transform}
          and period_end = ${last_period}
        order by pipeline_version desc
        limit 1;
      `);
      const z = zq.rows[0]?.level_z ?? null;

      const vsPrior = (currentVal != null && priorVal != null)
        ? Number(currentVal) - Number(priorVal)
        : null;

      const spark = await spark12m(series_id, default_transform);

      out.push({
        seriesId: series_id,
        displayName: display_name,
        transform: default_transform,
        unit: standard_unit,
        period: String(last_period),
        current: currentVal,
        prior: priorVal,
        vsPrior,
        zScore: z,
        spark12m: spark
      });
    }

    await setCache(cacheKey, out, MOVERS.CACHE_TTL_ECON_MS);
    await setLastGood(cacheKey, out);
    return res.json({ success: true, data: out });
  } catch (err) {
    console.error('[movers/econ] error', err);
    const last = await getLastGood(cacheKey);
    if (last) return res.json({ success: true, data: last, warning: 'stale_lastGood' });
    return res.json({ success: true, data: [], warning: 'data_unavailable' });
  }
};
```

**Routes**

```ts
router.get('/api/movers/etf', getEtfMovers);
router.get('/api/movers/econ', getEconMovers);
```

---

# 3) Quick verification (before checking the UI)

Run these locally:

```bash
curl -s "http://localhost:PORT/api/movers/etf?universe=SPY,XLK,XLF&limit=6" | jq
curl -s "http://localhost:PORT/api/movers/econ?limit=5" | jq
```

**Expected:** HTTP 200, `{ success:true, data: … }`. If you still get the error UI, check the Network tab—if the status is 500/404, paste the server log line here.

---

# 4) Frontend guard (avoid scary error card)

Make sure the tiles only show the big error state **when the request fails**, not when `data.signals.length === 0`.

```tsx
const { data, isError } = useQuery(...);

if (isError) {
  return <ErrorTile title="ETF Movers" subtitle="Unable to load…"/>;
}

if (!data) return <Skeleton />;

// show “No signals right now” when arrays are empty
```

Same for Econ Movers.

---

If you’d like, I can also push a tiny PR that includes these controller changes and a quick UI tweak so an empty result shows a gentle “No signals right now” state instead of the hard error panel.
