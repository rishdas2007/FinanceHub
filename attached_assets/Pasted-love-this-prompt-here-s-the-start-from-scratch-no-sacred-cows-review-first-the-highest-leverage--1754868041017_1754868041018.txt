love this prompt. here’s the “start-from-scratch, no sacred cows” review—first the highest-leverage architecture changes, then a database/schema redesign that matches your dashboard’s purpose, and finally a crisp implementation plan (with safe rollout + backfills).

---

# Prioritized changes (from first principles)

1. **Freeze the API contract + DTOs (stop shape drift)**

   * One response envelope: `{ success: true, data, warning?, cached?, version? }`.
   * One typed DTO per route (zod/io-ts on the server; generated TS types for the client).
   * Publish a tiny OpenAPI spec (or TS types package) and treat it as the contract of record.

2. **Move all heavy math off request path**

   * Precompute RSI/MACD/Bollinger/z-scores **daily** (plus a 5-min “intraday-lite” job if you must).
   * Requests should do joins + light filtering only. No per-request rolling windows.

3. **Separate intraday “quotes” from daily “bars” (and never mix)**

   * Intraday = *ephemeral* (`quote_snapshots`, short TTL cache).
   * Daily = *authoritative* (`daily_bars` table). All technicals/z-scores derive from daily.

4. **Adopt Bronze→Silver→Gold for macro—and only read Silver/Gold at runtime**

   * Bronze: as-published raw.
   * Silver: standardized units + alignment (month-end), single transform (LEVEL/YOY/…).
   * Gold: `level_z`, `change_z`, `classes`, `multi_signal`—with `pipeline_version`.

5. **Unified number formatting in the client**

   * One formatter driven by `(standard_unit, scale_hint, precision)`—no component math.

6. **Make caching explicit and versioned**

   * Hot TTL caches (30–300s) + “lastGood” snapshots (≤10m).
   * Cache keys carry `vX` and `pipeline_version` to avoid cross-deploy pollution.

7. **UTC everywhere + end-exclusive ranges**

   * DB stores TIMESTAMPTZ; server builds UTC midnight bounds; charts get `{ t: ms, date: 'YYYY-MM-DD' }`.

8. **Observability that catches data rot, not just 500s**

   * Count of symbols with `MIN_OBS < 180`, `sd≈0`, and fallback rows.
   * Dash health shows “% symbols with valid features” + “macro ETL recency”.

9. **Kill all “sample/legacy” fabrication paths**

   * If inputs are degenerate, return `fallback:true` and hide composites in the UI. Never invent numbers.

10. **Pluggable cache boundary (in-mem → Redis)**

* Keep current in-memory cache but code to an interface so you can switch to Redis if you scale beyond one process.

---

# Database & schema review (keep / change / add)

## Equities (sector ETFs)

### Keep

* A historical OHLCV table with `(symbol, ts_utc)` and numeric columns.

### Change

* **Rename & index** for clarity and speed:

  * `historical_stock_data` → `equity_daily_bars`
  * PK: `(symbol, ts_utc)`; index `(symbol, ts_utc DESC)`
* **Create a feature store** (no more scattered columns):

  * `equity_features_daily` keyed by `(symbol, asof_date, horizon, pipeline_version)` with one row per metric set.

### Add

```sql
-- Authoritative daily bars (UTC)
create table equity_daily_bars (
  symbol text not null,
  ts_utc timestamptz not null,            -- bar time @ 00:00:00Z
  open double precision not null,
  high double precision not null,
  low  double precision not null,
  close double precision not null,
  volume bigint,
  primary key (symbol, ts_utc)
);
create index idx_edb_symbol_desc on equity_daily_bars (symbol, ts_utc desc);

-- Intraday quotes (ephemeral, optional persistence)
create table quote_snapshots (
  symbol text not null,
  ts_utc timestamptz not null,
  price double precision not null,
  change double precision,
  percent_change double precision,
  volume bigint,
  market_cap bigint,
  primary key (symbol, ts_utc)
);

-- Precomputed technicals & composites
create table equity_features_daily (
  symbol text not null,
  asof_date date not null,
  horizon text not null,                   -- '20D'|'60D'|'252D'|'RSI14' etc
  rsi14 double precision,
  macd double precision,
  macd_signal double precision,
  boll_up double precision,
  boll_mid double precision,
  boll_low double precision,
  z_close double precision,                -- z-score vs lookback mean/sd
  sma20 double precision,
  sma50 double precision,
  sma200 double precision,
  extras jsonb not null default '{}'::jsonb,
  pipeline_version text not null,
  primary key (symbol, asof_date, horizon, pipeline_version)
);
create index idx_efd_symbol_date on equity_features_daily (symbol, asof_date desc);
```

**Rationale:**

* Daily bars are the single source for all TA.
* Features are versioned and queryable by `asof_date` and `horizon`—perfect for the table and charts.
* Intraday is separate, so you never contaminate daily computations.

---

## Macro (FRED/BLS/BEA)

### Keep (conceptually)

* Bronze/Silver/Gold layering and a `series_def` metadata table.

### Change

* **Enforce transforms as first-class keys**: if you display Core CPI YoY, treat it as its own `series_id` (`core_cpi_yoy`) or store `transform_code` in the PK.
* **Strict canonical units** in Silver (`PCT_DECIMAL`, `USD`, `COUNT`, `INDEX_PT`, `HOURS`, `RATIO_DECIMAL`).
* **Gold** stores only `level_z`, `change_z`, classes, and `multi_signal`. No “delta-adjusted z-score” variants.

### Add / finalize

```sql
create table econ_series_def (
  series_id text primary key,              -- e.g., 'core_cpi_yoy'
  display_name text not null,
  category text not null,
  type_tag text not null,                  -- Leading|Coincident|Lagging
  native_unit text not null,
  standard_unit text not null,             -- enum in app
  scale_hint text not null default 'NONE', -- NONE|K|M|B
  display_precision int not null default 2,
  default_transform text not null,         -- LEVEL|YOY|MOM|...
  align_policy text not null default 'last', -- for W→M
  preferred_window_months int not null default 60,
  seasonal_adj text not null,              -- SA|NSA
  source text not null,
  source_url text
);

create table econ_series_observation (
  series_id text references econ_series_def(series_id),
  period_start date not null,
  period_end date not null,
  freq text not null,                      -- W|M|Q
  value_std double precision not null,     -- canonical numeric
  standard_unit text not null,
  agg_method text not null,
  scale_hint text not null,
  display_precision int not null,
  transform_code text not null,
  primary key (series_id, period_end, transform_code)
);
create index idx_eso_series_end on econ_series_observation (series_id, period_end desc);

create table econ_series_features (
  series_id text references econ_series_def(series_id),
  period_end date not null,
  transform_code text not null,
  ref_window_months int not null,
  value_t double precision not null,
  delta_t double precision not null,
  mean_level double precision not null,
  sd_level double precision not null,
  mean_delta double precision not null,
  sd_delta double precision not null,
  level_z double precision not null,
  change_z double precision not null,
  level_class text not null,
  trend_class text not null,
  multi_signal text not null,
  pipeline_version text not null,
  provenance jsonb not null,
  primary key (series_id, period_end, transform_code, pipeline_version)
);
```

**Rationale:**

* UI and APIs can always read **Silver** for numbers and **Gold** for signals, with unit-safe formatting.
* Classes and multi-signal logic live in Gold (consistent everywhere).

---

# API surface (optimized for the dashboard)

* `GET /api/market-status` → `{ isOpen, nextOpen, label }`
* `GET /api/top-movers?universe=...` → `{ gainers[], losers[] }`
* `GET /api/sectors` → sector snapshot list (from quotes cache)
* `GET /api/etf-metrics?symbols=...` → rows from `equity_features_daily` + latest close (no on-the-fly TA)
* `GET /api/stocks/:symbol/history?window=7D|30D|90D|1Y|3Y|MAX` → DB→provider fallback, daily bars only
* `GET /api/sparkline?symbol=...&days=30` → thin `close` series from daily bars
* `GET /api/econ/indicators` → **Silver + Gold merge** (current/prior + z-scores/classes)
* `GET /api/econ/observations?seriesId=...&months=...` → chart series
* `GET /api/econ/insights?threshold=1.0` → top movement signals from Gold
* `GET /api/health` → `{ ok, db, provider, lastEtlAt }`

Every route: `{ success: true, data, warning?, cached?, version? }`.

---

# Implementation plan (safe rollout)

## Phase 0 — Contracts & guardrails (1–2 days)

* Add zod validators per route & generate client TS types.
* Lock response envelope; remove all `{error:...}`/`null`.
* Add request/response logging (size-capped JSON only).

## Phase 1 — Equities refactor (3–5 days)

* **Migrations**: create `equity_daily_bars`, `equity_features_daily`, `quote_snapshots`.
* **Backfill**: copy/rename from `historical_stock_data`; compute features for last 400 trading days (RSI/MACD/Bollinger + `z_close` for 20/60/252).
* **API swap**:

  * `/api/etf-metrics` → reads `equity_features_daily` + latest close.
  * `/api/stocks/:symbol/history` → DB first; provider fallback; return `{t,date,close}`.
* **UI**: numeric X-axis; badges for `fallback:true`; no fabricated values.

## Phase 2 — Macro Bronze/Silver/Gold (4–6 days)

* **Migrations**: `econ_series_def`, `econ_series_observation`, `econ_series_features`.
* **ETL**: Bronze ingest → Silver standardizer → Gold features (60-month windows).
* **API**:

  * `/api/econ/indicators` merges Silver+Gold.
  * `/api/econ/observations` returns chart series.
  * Add compat alias for legacy metric routes.
* **UI**: use single formatter; remove component transforms.

## Phase 3 — Caching & resiliency (1–2 days)

* Versioned keys, TTLs, and 10-minute lastGood snapshots.
* Circuit breakers + provider timeouts.
* Health endpoint includes `%valid_features` and `lastEtlAt` per domain.

## Phase 4 — Cleanups (nice-to-haves)

* OpenAPI doc or TS types package.
* Optional Redis cache adapter.
* Materialized views for the ETF table if needed.

---

# Acceptance criteria (what “done right” looks like)

* **ETF table**: loads in <150ms from cache; 0 fabricated values; any missing row displays `fallback:true` badge.
* **History charts**: correct date ranges; switching 7D/30D/90D changes point counts; no `.toISOString()` errors (X-axis numeric).
* **Economic table/cards**: consistent units/precision; classes match Gold; “Multi-signal” grid uses one rule everywhere.
* **Logs/metrics**: per-request source `{source:'db'|'provider', rows, ms}`; alerts fire on `% fallback rows > X%` or `sd≈0` counts.
* **Repro**: a single script can rebuild features for last N days (idempotent ETL).

---

# Quick “do this now” checklist (fast wins)

* ✅ Create `equity_features_daily` + backfill 252 days for SPY/XLK/XLF (prove speed & stability).
* ✅ Switch `/api/etf-metrics` to **read-only** from that table (no per-request math).
* ✅ Turn on the unit formatter for every number in macro tables; remove component transforms.
* ✅ Add `%valid_features` and `lastEtlAt` to `/api/health` so you can see data quality at a glance.

---

If you want, I can draft the Drizzle migration files + skeleton ETL jobs for **Phase 1** (equities) so you can run a local backfill and flip the `/api/etf-metrics` endpoint without touching the UI.
