Based on your schema analysis, here are the critical tables needed for the backfill operation:

  ---
  üéØ TIER 1: CORE BACKFILL TABLES (Essential)

  1. Historical Stock Data

  -- PRIORITY: CRITICAL
  historicalStockData = pgTable("historical_stock_data", {
    id, symbol, open, high, low, close, volume, date, createdAt
  })
  Purpose: Primary OHLCV data from Twelve Data APIStorage: ~63 KB per symbol per yearBackfill Target: 5 years √ó 15 symbols = ~4.7 MB

  2. Historical Technical Indicators

  -- PRIORITY: CRITICAL
  historicalTechnicalIndicators = pgTable("historical_technical_indicators", {
    id, symbol, rsi, macd, macdSignal, bb_upper, bb_middle, bb_lower,
    percent_b, adx, stoch_k, stoch_d, atr, date, createdAt
  })
  Purpose: Technical indicators from Twelve Data APIStorage: ~158 KB per symbol per yearBackfill Target: 5 years √ó 15 symbols = ~11.8 MB

  3. Z-Score Technical Indicators

  -- PRIORITY: CRITICAL
  zscoreTechnicalIndicators = pgTable("zscore_technical_indicators", {
    id, symbol, date, rsi, macd, percentB, atr, priceChange, maTrend,
    rsiZScore, macdZScore, bollingerZScore, atrZScore, priceMomentumZScore,
    maTrendZScore, compositeZScore, signal, signalStrength, lookbackPeriod,
    dataQuality, createdAt, updatedAt
  })
  Purpose: Calculated z-scores for trading signalsStorage: ~119 KB per symbol per yearBackfill Target: 5 years √ó 15 symbols = ~8.9 MB

  4. Historical Economic Data

  -- PRIORITY: CRITICAL
  historicalEconomicData = pgTable("historical_economic_data", {
    id, seriesId, indicator, value, category, frequency,
    releaseDate, periodDate, unit, createdAt
  })
  Purpose: Economic indicators from FRED APIStorage: ~50 KB per indicator for 10 yearsBackfill Target: 10 years √ó 80 indicators = ~4 MB

  ---
  üéØ TIER 2: SUPPORTING TABLES (Important)

  5. Data Collection Audit

  -- PRIORITY: HIGH
  dataCollectionAudit = pgTable("data_collection_audit", {
    id, dataType, symbol, collectionDate, recordsProcessed,
    apiCallsUsed, status, errorMessage, dataRangeStart,
    dataRangeEnd, processingTimeMs, createdAt
  })
  Purpose: Track backfill progress and API usageStorage: ~1 KB per backfill operationBackfill Target: ~100 records = ~100 KB

  6. Historical Market Sentiment

  -- PRIORITY: MEDIUM
  historicalMarketSentiment = pgTable("historical_market_sentiment", {
    id, vix, vixChange, putCallRatio, aaiiBullish, aaiiBearish,
    aaiiNeutral, date, dataSource, createdAt
  })
  Purpose: VIX and sentiment data for volatility regime detectionStorage: ~25 KB per yearBackfill Target: 5 years = ~125 KB

  7. Historical Sector Data

  -- PRIORITY: MEDIUM
  historicalSectorData = pgTable("historical_sector_data", {
    id, sectorName, performance, volume, marketCap, date, createdAt
  })
  Purpose: Sector performance trackingStorage: ~30 KB per sector per yearBackfill Target: 5 years √ó 11 sectors = ~1.65 MB

  ---
  üéØ TIER 3: OPTIONAL TABLES (Can Skip Initially)

  8. Rolling Statistics ‚ùå SKIP

  -- PRIORITY: LOW (Currently unused)
  rollingStatistics = pgTable("rolling_statistics", ...)
  Status: Your earlier analysis showed this is completely unused. Skip for backfill.

  9. Economic Time Series ‚ùå SKIP

  -- PRIORITY: LOW (Duplicate of historicalEconomicData)
  economicTimeSeries = pgTable("economic_time_series", ...)
  Status: Redundant with historicalEconomicData. Skip to avoid duplication.

  10. Data Lineage Log ‚ùå SKIP

  -- PRIORITY: LOW (Operational monitoring)
  dataLineageLog = pgTable("data_lineage_log", ...)
  Status: Useful for debugging but not essential for backfill functionality.

  ---
  üìä BACKFILL STORAGE REQUIREMENTS

  Total Storage Estimate

  const STORAGE_REQUIREMENTS = {
    tier1_essential: {
      historicalStockData: '4.7 MB',
      historicalTechnicalIndicators: '11.8 MB',
      zscoreTechnicalIndicators: '8.9 MB',
      historicalEconomicData: '4.0 MB',
      subtotal: '29.4 MB'
    },

    tier2_supporting: {
      dataCollectionAudit: '0.1 MB',
      historicalMarketSentiment: '0.125 MB',
      historicalSectorData: '1.65 MB',
      subtotal: '1.875 MB'
    },

    total_required: '31.3 MB',  // Very manageable for Neon Pro
    neon_free_limit: '512 MB',  // You have plenty of space
    neon_pro_limit: '10 GB'     // Massive headroom for growth
  };

  ---
  üóÉÔ∏è REQUIRED TABLE CREATION SCRIPT

  Ensure these tables exist before running backfill:

  -- Verify essential tables exist
  SELECT table_name
  FROM information_schema.tables
  WHERE table_schema = 'public'
  AND table_name IN (
    'historical_stock_data',
    'historical_technical_indicators',
    'zscore_technical_indicators',
    'historical_economic_data',
    'data_collection_audit',
    'historical_market_sentiment',
    'historical_sector_data'
  );

  -- Create missing indices for performance
  CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_historical_stock_symbol_date
  ON historical_stock_data(symbol, date DESC);

  CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_historical_tech_symbol_date
  ON historical_technical_indicators(symbol, date DESC);

  CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_zscore_symbol_date
  ON zscore_technical_indicators(symbol, date DESC);

  CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_economic_series_period
  ON historical_economic_data(series_id, period_date DESC);

  ---
  üö¶ BACKFILL EXECUTION ORDER

  Recommended Table Population Sequence:

  1. historical_stock_data ‚Üê Twelve Data OHLCV
  2. historical_economic_data ‚Üê FRED economic indicators
  3. historical_technical_indicators ‚Üê Twelve Data technical analysis
  4. historical_market_sentiment ‚Üê VIX data
  5. historical_sector_data ‚Üê Sector ETF performance
  6. zscore_technical_indicators ‚Üê Calculated from technical data
  7. data_collection_audit ‚Üê Progress tracking

  Parallel Execution Strategy:

  - Stream 1: Steps 1, 3, 4, 5 (Twelve Data API)
  - Stream 2: Step 2 (FRED API)
  - Stream 3: Steps 6, 7 (Post-processing)

  ---
  ‚úÖ PRE-BACKFILL CHECKLIST

  Before running backfill, verify:

  - All 7 essential tables exist in database
  - Performance indices are created
  - Database has sufficient storage (31.3 MB required)
  - API keys are configured (TWELVE_DATA_API_KEY, FRED_API_KEY)
  - Rate limiting service is configured
  - Bulk data service is implemented

  Bottom Line: You need 7 core tables consuming only ~31 MB of storage. Your current Neon setup can easily handle this backfill operation with room for 16x growth before hitting any limits.